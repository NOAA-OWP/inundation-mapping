{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2041788",
   "metadata": {},
   "source": [
    "## Make ras2fim/ripple boundary dataset\n",
    "\n",
    "###### This comes in two parts, it will load all of the stats.csv from the ripple downloads, which are often split into smaller groups. ie) for FIM30, there was 485 MC (model collections), but they were downloaded in sets of 50. \n",
    "\n",
    "Last edited: Mar 5, 2025\n",
    "\n",
    "*** Processing steps\n",
    "1) Load all of the ripple stats csvs\n",
    "   \n",
    "2) load the old ras2fm v2 data. At this point, we don't have a specific dataset for ras2fim that has the huc number and number of models included. We will make a simple csv with columns of HUC and model_count.\n",
    "\n",
    "3) Merge the ripple and ras2fim df together\n",
    "\n",
    "4) Make a new dataframe starting with just unique HUCs. Each HUC can iterate back through the original merged df and look for the count of models for ripple mip, ripple ble and ras2fim\n",
    "\n",
    "5) save as csv and gpkg  (csv for HV and gkpg for easy visual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eedeaa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading imports\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import stat\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Display all rows\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_rows', 10)\n",
    "\n",
    "# Display all columns\n",
    "pd.set_option('display.max_columns', 10)\n",
    "\n",
    "# Display full width of columns\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(\"Done loading imports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c933e3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading global variables\n"
     ]
    }
   ],
   "source": [
    "# GLOBAL VARIABLES\n",
    "# NOTE: Careful about checking some of this in if it has actual server names or paths\n",
    "\n",
    "ROOT_PATH = \"/{fill in}\"\n",
    "RIPPLE_STATS_CSV_DIR = f\"{ROOT_PATH}/fim-data/ripple/fim_30_prod_data/stats_csv_temp/\"\n",
    "RAS2FIM_STATUS_FILE = f\"{ROOT_PATH}/fim-data/ripple/fim_30_prod_data/ras2fim_v2_huc_list_w_feature_counts.csv\"\n",
    "OUTPUT_CSV_path = \"/{fill in}/outputs/hecras_boundaries.csv\"\n",
    "\n",
    "is_verbose = False\n",
    "\n",
    "print(\"Done loading global variables\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e1829e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ripple csv's\n",
    "\n",
    "stats_files = glob.glob(RIPPLE_STATS_CSV_DIR + \"*.csv\")\n",
    "df_ripple_stats_files = []\n",
    "\n",
    "for filename in stats_files:\n",
    "    df = pd.read_csv(filename,\n",
    "                     index_col=None,\n",
    "                     usecols=['huc', 'source', 'num_features'],\n",
    "                     dtype={'huc': str})\n",
    "    df_ripple_stats_files.append(df)\n",
    "\n",
    "df_ripple_stats = pd.concat(df_ripple_stats_files, ignore_index=True)\n",
    "\n",
    "if is_verbose:\n",
    "    print(df_ripple_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba92f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ras2fim data\n",
    "df_ras2fim = pd.read_csv(RAS2FIM_STATUS_FILE,\n",
    "                         index_col=None,\n",
    "                         dtype={'huc': str})\n",
    "df_ras2fim[\"source\"] = \"ras2fim\"\n",
    "if is_verbose:\n",
    "    print(df_ras2fim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cf0cb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = pd.concat([df_ripple_stats, df_ras2fim], ignore_index=True)\n",
    "\n",
    "df_stats['huc'] = df_stats['huc'].str.zfill(8)\n",
    "\n",
    "if is_verbose:\n",
    "    print(df_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46f54cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Category' and pivot 'Item' to columns\n",
    "df_pivot = df_stats.pivot_table(index='huc', columns='source', values='num_features')\n",
    "\n",
    "df_pivot[\"ble\"].fillna(\"0\", inplace = True)\n",
    "df_pivot[\"mip\"].fillna(\"0\", inplace = True)\n",
    "df_pivot[\"ras2fim\"].fillna(\"0\", inplace = True)\n",
    "\n",
    "df_pivot['ble'] = df_pivot['ble'].astype(int)\n",
    "df_pivot['mip'] = df_pivot['mip'].astype(int)\n",
    "df_pivot['ras2fim'] = df_pivot['ras2fim'].astype(int)\n",
    "\n",
    "# drop blank rows\n",
    "df_pivot = df_pivot[ ((df_pivot[\"ble\"] > 0) | (df_pivot[\"mip\"] > 0) | (df_pivot[\"ras2fim\"] > 0)) ]\n",
    "\n",
    "if is_verbose:\n",
    "    print(df_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d60856b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# just testing\n",
    "#df = df_pivot.loc[df_pivot['ble'] > 0]\n",
    "# df_pivot.loc[(df_pivot['mip'] == 0) & (df_pivot['ble'] > 0) ]\n",
    "# df_pivot.loc[df_pivot['ras2fim'] > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26b6b0d5-e558-42ee-a11d-c9a5b466a587",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find the source with the highest number of features.\n",
    "cols_to_check = ['ble', 'mip', 'ras2fim']\n",
    "# df_pivot[\"selected_source\"] = \n",
    "df_pivot[\"selected_source\"] = df_pivot[cols_to_check].idxmax(axis=1)\n",
    "\n",
    "if is_verbose:\n",
    "    print(df_pivot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95d8ce89-4aa8-447a-a80a-a3ef5ac5c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table adjustments\n",
    "df_pivot.rename(columns={\"ble\": \"num_ble_features\", \"mip\": \"num_mip_features\", \"ras2fim\": \"num_ras2fim_features\"}, inplace=True)\n",
    "df_pivot[\"is_active\"] = \"True\"\n",
    "if is_verbose:\n",
    "    print(df_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8653a731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_pivot saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_pivot.to_csv(OUTPUT_CSV_path)\n",
    "os.chmod(OUTPUT_CSV_path, stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO)\n",
    "print(\"df_pivot saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
