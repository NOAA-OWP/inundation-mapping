{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2041788",
   "metadata": {},
   "source": [
    "## Make ras2fim/ripple boundary dataset\n",
    "\n",
    "###### This comes in two parts, it will load all of the stats.csv from the ripple downloads, which are often split into smaller groups. ie) for FIM30, there was 485 MC (model collections), but they were downloaded in sets of 50. \n",
    "\n",
    "Last edited: Mar 5, 2025\n",
    "\n",
    "*** Processing steps\n",
    "1) Load all of the ripple stats csvs\n",
    "   \n",
    "2) load the old ras2fm v2 data. At this point, we don't have a specific dataset for ras2fim that has the huc number and number of models included. We will make a simple csv with columns of HUC and model_count.\n",
    "\n",
    "3) Merge the ripple and ras2fim df together\n",
    "\n",
    "4) Make a new dataframe starting with just unique HUCs. Each HUC can iterate back through the original merged df and look for the count of models for ripple mip, ripple ble and ras2fim\n",
    "\n",
    "5) save as csv and gpkg  (csv for HV and gkpg for easy visual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eedeaa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading imports\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import stat\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Display all rows\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_rows', 10)\n",
    "\n",
    "# Display all columns\n",
    "pd.set_option('display.max_columns', 10)\n",
    "\n",
    "# Display full width of columns\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(\"Done loading imports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c933e3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading global variables\n"
     ]
    }
   ],
   "source": [
    "# GLOBAL VARIABLES\n",
    "\n",
    "# *****************************\n",
    "# NOTE: Careful about checking some of this in if it has actual server names or paths\n",
    "ROOT_PATH = \"/efs-drives/fim-dev-efs\"\n",
    "# *****************************\n",
    "\n",
    "WBD_HUC8_FILE_PATH = f\"{ROOT_PATH}/fim-data/inputs/wbd/WBD_National_HUC8_EPSG_5070_HAND_domain.gpkg\"\n",
    "\n",
    "RIPPLE_STATS_CSV_DIR = f\"{ROOT_PATH}/fim-data/ripple/fim_30_prod_data/stats_csv_temp/\"\n",
    "RAS2FIM_STATUS_FILE = f\"{ROOT_PATH}/fim-data/ripple/fim_30_prod_data/ras2fim_v2_huc_list_w_feature_counts.csv\"\n",
    "OUTPUT_CSV_path = \"/home/rdp-user/outputs/hecras_boundaries.csv\"\n",
    "\n",
    "is_verbose = True\n",
    "\n",
    "print(\"Done loading global variables\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e1829e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    source      huc  num_features\n",
      "0      ble  8040205            48\n",
      "1      mip  8040302            51\n",
      "2      mip  8040303           128\n",
      "3      mip  8040304            22\n",
      "4      mip  8060202            92\n",
      "..     ...      ...           ...\n",
      "480    mip  8030207           171\n",
      "481    ble  8040101            75\n",
      "482    mip  8040101             4\n",
      "483    ble  8040203           159\n",
      "484    mip  8040204             1\n",
      "\n",
      "[485 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load ripple csv's\n",
    "\n",
    "stats_files = glob.glob(RIPPLE_STATS_CSV_DIR + \"*.csv\")\n",
    "df_ripple_stats_files = []\n",
    "\n",
    "for filename in stats_files:\n",
    "    df = pd.read_csv(filename,\n",
    "                     index_col=None,\n",
    "                     usecols=['huc', 'source', 'num_features'],\n",
    "                     dtype={'huc': str})\n",
    "    df_ripple_stats_files.append(df)\n",
    "\n",
    "df_ripple_stats = pd.concat(df_ripple_stats_files, ignore_index=True)\n",
    "\n",
    "if is_verbose:\n",
    "    print(df_ripple_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba92f530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         huc  num_features   source\n",
      "0   12010005           947  ras2fim\n",
      "1   12030101           607  ras2fim\n",
      "2   12030103           466  ras2fim\n",
      "3   12030105           247  ras2fim\n",
      "4   12030106           352  ras2fim\n",
      "5   12030108           377  ras2fim\n",
      "6   12030201          1068  ras2fim\n",
      "7   12030202          1764  ras2fim\n",
      "8   12040101           619  ras2fim\n",
      "9   12070102           546  ras2fim\n",
      "10  12090301           898  ras2fim\n",
      "11  12100202            57  ras2fim\n"
     ]
    }
   ],
   "source": [
    "# Load the ras2fim data\n",
    "df_ras2fim = pd.read_csv(RAS2FIM_STATUS_FILE,\n",
    "                         index_col=None,\n",
    "                         dtype={'huc': str})\n",
    "df_ras2fim[\"source\"] = \"ras2fim\"\n",
    "if is_verbose:\n",
    "    print(df_ras2fim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cf0cb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      source       huc  num_features\n",
      "0        ble  08040205            48\n",
      "1        mip  08040302            51\n",
      "2        mip  08040303           128\n",
      "3        mip  08040304            22\n",
      "4        mip  08060202            92\n",
      "..       ...       ...           ...\n",
      "492  ras2fim  12030202          1764\n",
      "493  ras2fim  12040101           619\n",
      "494  ras2fim  12070102           546\n",
      "495  ras2fim  12090301           898\n",
      "496  ras2fim  12100202            57\n",
      "\n",
      "[497 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df_stats = pd.concat([df_ripple_stats, df_ras2fim], ignore_index=True)\n",
    "\n",
    "df_stats['huc'] = df_stats['huc'].str.zfill(8)\n",
    "\n",
    "if is_verbose:\n",
    "    print(df_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46f54cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source    ble  mip  ras2fim\n",
      "huc                        \n",
      "02040101    0  212        0\n",
      "02040103    0  208        0\n",
      "02040104    0  388        0\n",
      "02040105    0    3        0\n",
      "02040106    0  419        0\n",
      "...       ...  ...      ...\n",
      "17120002    0   23        0\n",
      "18010201    0   10        0\n",
      "18010202    0   80        0\n",
      "18010203    0    5        0\n",
      "18010204    0   61        0\n",
      "\n",
      "[435 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Group by 'Category' and pivot 'Item' to columns\n",
    "df_pivot = df_stats.pivot_table(index='huc', columns='source', values='num_features')\n",
    "\n",
    "df_pivot[\"ble\"].fillna(\"0\", inplace = True)\n",
    "df_pivot[\"mip\"].fillna(\"0\", inplace = True)\n",
    "df_pivot[\"ras2fim\"].fillna(\"0\", inplace = True)\n",
    "\n",
    "df_pivot['ble'] = df_pivot['ble'].astype(int)\n",
    "df_pivot['mip'] = df_pivot['mip'].astype(int)\n",
    "df_pivot['ras2fim'] = df_pivot['ras2fim'].astype(int)\n",
    "\n",
    "# drop blank rows\n",
    "df_pivot = df_pivot[ ((df_pivot[\"ble\"] > 0) | (df_pivot[\"mip\"] > 0) | (df_pivot[\"ras2fim\"] > 0)) ]\n",
    "\n",
    "if is_verbose:\n",
    "    print(df_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d60856b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# just testing\n",
    "#df = df_pivot.loc[df_pivot['ble'] > 0]\n",
    "# df_pivot.loc[(df_pivot['mip'] == 0) & (df_pivot['ble'] > 0) ]\n",
    "# df_pivot.loc[df_pivot['ras2fim'] > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26b6b0d5-e558-42ee-a11d-c9a5b466a587",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source    ble  mip  ras2fim selected_source\n",
      "huc                                        \n",
      "02040101    0  212        0             mip\n",
      "02040103    0  208        0             mip\n",
      "02040104    0  388        0             mip\n",
      "02040105    0    3        0             mip\n",
      "02040106    0  419        0             mip\n",
      "...       ...  ...      ...             ...\n",
      "17120002    0   23        0             mip\n",
      "18010201    0   10        0             mip\n",
      "18010202    0   80        0             mip\n",
      "18010203    0    5        0             mip\n",
      "18010204    0   61        0             mip\n",
      "\n",
      "[435 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# find the source with the highest number of features.\n",
    "cols_to_check = ['ble', 'mip', 'ras2fim']\n",
    "# df_pivot[\"selected_source\"] = \n",
    "df_pivot[\"selected_source\"] = df_pivot[cols_to_check].idxmax(axis=1)\n",
    "\n",
    "if is_verbose:\n",
    "    print(df_pivot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95d8ce89-4aa8-447a-a80a-a3ef5ac5c32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source    num_ble_features  num_mip_features  num_ras2fim_features  \\\n",
      "huc                                                                  \n",
      "02040101                 0               212                     0   \n",
      "02040103                 0               208                     0   \n",
      "02040104                 0               388                     0   \n",
      "02040105                 0                 3                     0   \n",
      "02040106                 0               419                     0   \n",
      "...                    ...               ...                   ...   \n",
      "17120002                 0                23                     0   \n",
      "18010201                 0                10                     0   \n",
      "18010202                 0                80                     0   \n",
      "18010203                 0                 5                     0   \n",
      "18010204                 0                61                     0   \n",
      "\n",
      "source   selected_source is_active  \n",
      "huc                                 \n",
      "02040101             mip      True  \n",
      "02040103             mip      True  \n",
      "02040104             mip      True  \n",
      "02040105             mip      True  \n",
      "02040106             mip      True  \n",
      "...                  ...       ...  \n",
      "17120002             mip      True  \n",
      "18010201             mip      True  \n",
      "18010202             mip      True  \n",
      "18010203             mip      True  \n",
      "18010204             mip      True  \n",
      "\n",
      "[435 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# table adjustments\n",
    "df_pivot.rename(columns={\"ble\": \"num_ble_features\", \"mip\": \"num_mip_features\", \"ras2fim\": \"num_ras2fim_features\"}, inplace=True)\n",
    "df_pivot[\"is_active\"] = \"True\"\n",
    "if is_verbose:\n",
    "    print(df_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d5467eb-9ee6-4015-95e6-2494c29489ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rec count is 434\n"
     ]
    }
   ],
   "source": [
    "# Add geometries from the HUCs from the WBD\n",
    "\n",
    "# Load the WBD\n",
    "wbd = gpd.read_file(WBD_HUC8_FILE_PATH)[[\"HUC8\", \"geometry\"]]\n",
    "\n",
    "# merge with my csv  (gpd)\n",
    "boundaries_df = df_pivot.merge(wbd, left_on='huc', right_on='HUC8')\n",
    "\n",
    "if is_verbose:\n",
    "    # print(boundaries_df.head(1))\n",
    "    print(f\"Total Rec count is {len(boundaries_df)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a5cc2c-6bec-40e7-9fb1-89397a86debf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8653a731",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df_pivot.to_csv(OUTPUT_CSV_path)\n",
    "#os.chmod(OUTPUT_CSV_path, stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO)\n",
    "#print(\"df_pivot saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
