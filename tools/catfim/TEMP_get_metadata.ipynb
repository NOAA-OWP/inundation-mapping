{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "544d20bf-6273-4dd5-bae8-a42935b3e3f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed, wait\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from tools_shared_functions import (\n",
    "    aggregate_wbd_hucs,\n",
    "    filter_nwm_segments_by_stream_order,\n",
    "    flow_data,\n",
    "    get_metadata,\n",
    "    get_nwm_segs,\n",
    "    get_thresholds,\n",
    ")\n",
    "\n",
    "import utils.fim_logger as fl\n",
    "from utils.shared_variables import VIZ_PROJECTION\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dca1b28-976d-4487-9fd3-96253e1e83f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Testing get_metadata() functionality\n",
    "\n",
    "\n",
    "# --------- Inputs --------- \n",
    "\n",
    "\n",
    "search = 5\n",
    "\n",
    "nwm_us_search, nwm_ds_search = search, search\n",
    "\n",
    "\n",
    "# output_catfim_dir = \n",
    "API_BASE_URL = 'https://nwcal-wrds.nwc.nws.noaa.gov/api/location/v3.0'\n",
    "metadata_url = f'{API_BASE_URL}/metadata'\n",
    "\n",
    "\n",
    "# lid_to_run = \n",
    "# nwm_metafile = \n",
    "\n",
    "# --------- Code --------- \n",
    "\n",
    "all_meta_lists = []\n",
    "\n",
    "\n",
    "conus_list, ___ = get_metadata(\n",
    "    metadata_url,\n",
    "    select_by='nws_lid',\n",
    "    selector=['all'],\n",
    "    must_include='nws_data.rfc_forecast_point',\n",
    "    upstream_trace_distance=nwm_us_search,\n",
    "    downstream_trace_distance=nwm_ds_search,\n",
    ")\n",
    "\n",
    "\n",
    "# Get metadata for Islands and Alaska\n",
    "islands_list, ___ = get_metadata(\n",
    "    metadata_url,\n",
    "    select_by='state',\n",
    "    selector=['HI', 'PR', 'AK'],\n",
    "    must_include=None,\n",
    "    upstream_trace_distance=nwm_us_search,\n",
    "    downstream_trace_distance=nwm_ds_search,\n",
    ")\n",
    "# Append the lists\n",
    "all_meta_lists = conus_list + islands_list\n",
    "\n",
    "# print(islands_list)\n",
    "\n",
    "# with open(meta_file, \"wb\") as p_handle:\n",
    "#     pickle.dump(all_meta_lists, p_handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a27ec31-f7d3-4fba-943b-362f848813fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of conus_list: 4679\n",
      "Length of islands_list: 2952\n",
      "Length of all_meta_lists: 7631\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of conus_list: {len(conus_list)}')\n",
    "print(f'Length of islands_list: {len(islands_list)}')\n",
    "print(f'Length of all_meta_lists: {len(all_meta_lists)}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d25a4979-2b0c-4f4f-ae41-6fec3768d39b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input metadata list length: 7631\n",
      "Output (unique) metadata list length: 7214\n",
      "Number of unique LIDs: 7214 \n",
      "Number of duplicate LIDs: 152 \n",
      "Number of None LIDs: 265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------ New addition: filtering ------\n",
    "\n",
    "\n",
    "\n",
    "# -- function --\n",
    "def filter_metadata_list (metadata_list, verbose):\n",
    "    '''\n",
    "    \n",
    "    Filter metadata list to remove: \n",
    "    - sites where the nws_lid = None\n",
    "    - duplicate sites\n",
    "    \n",
    "    '''\n",
    "\n",
    "    unique_lids, duplicate_lids = [], []\n",
    "    duplicate_metadata_list, unique_metadata_list = [], []\n",
    "    \n",
    "    nonelid_metadata_list = [] # TODO: remove eventually?    \n",
    "\n",
    "    for i, site in enumerate(metadata_list):\n",
    "        nws_lid = site['identifiers']['nws_lid']\n",
    "\n",
    "        if nws_lid == None:\n",
    "            # No LID available\n",
    "            nonelid_metadata_list.append(site)\n",
    "            \n",
    "            # TODO: replace this with Continue, eventually we wont need this list\n",
    "        \n",
    "        elif nws_lid in unique_lids:\n",
    "            # Duplicate LID\n",
    "            duplicate_lids.append(nws_lid)\n",
    "            duplicate_metadata_list.append(site)\n",
    "            \n",
    "        else: \n",
    "            # Unique/unseen LID that's not None\n",
    "            unique_lids.append(nws_lid)\n",
    "            unique_metadata_list.append(site)\n",
    "            \n",
    "    if verbose == True:\n",
    "        print(f'Input metadata list length: {len(metadata_list)}')\n",
    "        print(f'Output (unique) metadata list length: {len(unique_metadata_list)}')\n",
    "        print(f'Number of unique LIDs: {len(unique_lids)} \\nNumber of duplicate LIDs: {len(duplicate_lids)} \\nNumber of None LIDs: {len(nonelid_metadata_list)}')\n",
    "    \n",
    "    return unique_lids, duplicate_lids, nonelid_metadata_list, duplicate_metadata_list, unique_metadata_list # TODO: eventually, have it only return necessary objects\n",
    "\n",
    "\n",
    "\n",
    "unique_lids, duplicate_lids, nonelid_metadata_list, duplicate_metadata_list, unique_metadata_list =  filter_metadata_list(all_meta_lists, True)\n",
    "print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ffc3b60-18de-4825-8766-80f3904fd6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Code: Single API call (only forecast points)\n",
      "\n",
      "By-state site count:\n",
      "State: Puerto Rico \n",
      "Number of sites: 5\n",
      "\n",
      "Proposed Update: Double API call (forecast points + all HI, AK, and PR points\n",
      "\n",
      "By-state site count, before filtering out duplicates:\n",
      "State: Puerto Rico \n",
      "Number of sites: 243\n",
      "\n",
      "By-state site count, AFTER filtering out duplicates:\n",
      "State: Puerto Rico \n",
      "Number of sites: 238\n",
      "\n",
      "Current Code: Single API call (only forecast points)\n",
      "\n",
      "By-state site count:\n",
      "State: Hawaii \n",
      "Number of sites: 2\n",
      "\n",
      "Proposed Update: Double API call (forecast points + all HI, AK, and PR points\n",
      "\n",
      "By-state site count, before filtering out duplicates:\n",
      "State: Hawaii \n",
      "Number of sites: 497\n",
      "\n",
      "By-state site count, AFTER filtering out duplicates:\n",
      "State: Hawaii \n",
      "Number of sites: 495\n",
      "\n",
      "Current Code: Single API call (only forecast points)\n",
      "\n",
      "By-state site count:\n",
      "State: Alaska \n",
      "Number of sites: 145\n",
      "\n",
      "Proposed Update: Double API call (forecast points + all HI, AK, and PR points\n",
      "\n",
      "By-state site count, before filtering out duplicates:\n",
      "State: Alaska \n",
      "Number of sites: 2095\n",
      "\n",
      "By-state site count, AFTER filtering out duplicates:\n",
      "State: Alaska \n",
      "Number of sites: 1950\n"
     ]
    }
   ],
   "source": [
    "state_list = ['Puerto Rico', 'Hawaii', 'Alaska']\n",
    "\n",
    "for state in state_list: \n",
    "    print()\n",
    "    print('Current Code: Single API call (only forecast points)')\n",
    "    print()\n",
    "    print('By-state site count:')\n",
    "    currentcode_state = filter_by_state(state, conus_list, True)\n",
    "    print()\n",
    "    print('Proposed Update: Double API call (forecast points + all HI, AK, and PR points')\n",
    "    print()\n",
    "    print('By-state site count, before filtering out duplicates:')\n",
    "    prefilt_state = filter_by_state(state, all_meta_lists, True)\n",
    "    print()\n",
    "    print('By-state site count, AFTER filtering out duplicates:')\n",
    "    postfilt_state = filter_by_state(state, unique_metadata_list, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d2ad926-105c-4326-980c-3e4793b7b58a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: Connecticut \n",
      "Number of sites: 23\n",
      "State: New York \n",
      "Number of sites: 142\n",
      "State: Texas \n",
      "Number of sites: 380\n"
     ]
    }
   ],
   "source": [
    "postfilt_state = filter_by_state('Connecticut', unique_metadata_list, True)\n",
    "postfilt_state = filter_by_state('New York', unique_metadata_list, True)\n",
    "postfilt_state = filter_by_state('Texas', unique_metadata_list, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65996d68-b060-4cd3-b575-3e3d4172c532",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input metadata list length: 4679\n",
      "Output (unique) metadata list length: 4679\n",
      "Number of unique LIDs: 4679 \n",
      "Number of duplicate LIDs: 0 \n",
      "Number of None LIDs: 0\n",
      "State: Alaska \n",
      "Number of sites: 145\n"
     ]
    }
   ],
   "source": [
    "## Current code formulation\n",
    "\n",
    "\n",
    "unique_lids, duplicate_lids, nonelid_metadata_list, duplicate_metadata_list, unique_metadata_list =  filter_metadata_list(conus_list, True)\n",
    "print()\n",
    "conus_list_filt = filter_by_state('Alaska', conus_list, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "dcd1a64b-35c3-4f75-9e08-e936c17da1bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LID filter: None \n",
      "Number of sites: 265\n"
     ]
    }
   ],
   "source": [
    "# lid_list, duplicate_lid_list = list_duplicate_lids(all_meta_lists, True)\n",
    "\n",
    "conus_list_filt = filter_by_lid(None, islands_list, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68bee81b-f67f-48bf-8dd9-86f60dd3e6d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 \n",
      "Elapsed time: 16.981601495 16.980996046\n",
      "Elapsed time during the whole program in seconds: 0.0006054489999982593\n"
     ]
    }
   ],
   "source": [
    "from time import process_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "352ca99d-3b29-4ae9-848c-e2f55f9bebb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List length: 4679\n",
      "Runtime (seconds): 0.9184548869999993\n"
     ]
    }
   ],
   "source": [
    "t1_start = process_time() # stopwatch\n",
    " \n",
    "\n",
    "conus_list, ___ = get_metadata(\n",
    "    metadata_url,\n",
    "    select_by='nws_lid',\n",
    "    selector=['all'],\n",
    "    must_include='nws_data.rfc_forecast_point',\n",
    "    upstream_trace_distance=nwm_us_search,\n",
    "    downstream_trace_distance=nwm_ds_search,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print('List length:', len(conus_list))\n",
    "\n",
    "t1_stop = process_time() # stopwatch\n",
    "print('Runtime (seconds):', t1_stop-t1_start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dddc9047-5aa3-4459-ad12-3c9553850a17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00RDR'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conus_list[1]\n",
    "\n",
    "conus_list[1]['identifiers']['nws_lid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1c7d9207-9b2b-431b-ab4e-3dbb3e2107f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of LIDs: ['00BRD', '00RDR', '1TEST', 'AABDB', 'AACLA', 'AACLS', 'AAMEE', 'AANG1', 'AARVB', 'ABAT2', 'ABBG1']\n"
     ]
    }
   ],
   "source": [
    "def list_of_lids(conus_list, verbose):\n",
    "    '''\n",
    "    Extract a list of LIDs from the conus_list\n",
    "    '''\n",
    "    lid_list = []\n",
    "    for i, site in enumerate(conus_list):\n",
    "        nws_lid = site['identifiers']['nws_lid']\n",
    "        lid_list.append(nws_lid)\n",
    "    if verbose == True:\n",
    "        print(f'List of LIDs: {lid_list}')\n",
    "        \n",
    "    return lid_list\n",
    "\n",
    "\n",
    "\n",
    "lid_list = list_of_lids(conus_list, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "142b5809-a9a1-4797-800f-bf30e113413a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of unique LID list: 4679\n",
      "List of duplicate LIDs: []\n"
     ]
    }
   ],
   "source": [
    "def list_duplicate_lids(conus_list, verbose):\n",
    "    '''\n",
    "    Extract a list of duplicate LIDs from the conus_list\n",
    "    '''\n",
    "    lid_list = []\n",
    "    duplicate_lid_list = []\n",
    "     \n",
    "    \n",
    "    for i, site in enumerate(conus_list):\n",
    "        nws_lid = site['identifiers']['nws_lid']\n",
    "\n",
    "        if nws_lid in lid_list:\n",
    "            duplicate_lid_list.append(nws_lid)\n",
    "        else: \n",
    "            lid_list.append(nws_lid)\n",
    "\n",
    "    if verbose == True:\n",
    "        print(f'Length of unique LID list: {len(lid_list)}')\n",
    "        print(f'List of duplicate LIDs: {duplicate_lid_list}')\n",
    "\n",
    "        \n",
    "    return lid_list, duplicate_lid_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lid_list, duplicate_lid_list = list_duplicate_lids(conus_list, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4021e828-60dd-4483-9b13-4e8b5f2f6938",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LID filter: None \n",
      "Number of sites: 0\n"
     ]
    }
   ],
   "source": [
    "def filter_by_lid(lid_filter, conus_list, verbose):\n",
    "    '''\n",
    "    Function to filter conus_list by LID\n",
    "    '''\n",
    "    conus_list_filt = []\n",
    "    for i, site in enumerate(conus_list):\n",
    "        lid = site['identifiers']['nws_lid']\n",
    "        if lid == lid_filter:\n",
    "            conus_list_filt.append(site)\n",
    "    if verbose == True:\n",
    "        print(f'LID filter: {lid_filter} \\nNumber of sites: {len(conus_list_filt)}')\n",
    "        \n",
    "    return conus_list_filt\n",
    "\n",
    "\n",
    "\n",
    "conus_list_filt = filter_by_lid('None', conus_list, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5296eec6-8f5e-4ff7-bdfd-a5808fe960fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: Alaska \n",
      "Number of sites: 145\n"
     ]
    }
   ],
   "source": [
    "def filter_by_state(state_filter, conus_list, verbose):\n",
    "    '''\n",
    "    Function to filter conus_list by state\n",
    "    '''\n",
    "    conus_list_filt = []\n",
    "    for i, site in enumerate(conus_list):\n",
    "        state = site['nws_data']['state']\n",
    "        if state == state_filter:\n",
    "            conus_list_filt.append(site)\n",
    "    if verbose == True:\n",
    "        print(f'State: {state_filter} \\nNumber of sites: {len(conus_list_filt)}')\n",
    "        \n",
    "    return conus_list_filt\n",
    "\n",
    "\n",
    "\n",
    "conus_list_filt = filter_by_state('Alaska', conus_list, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ec188992-fda6-4f8b-876f-be78c48c67cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "state_list, ___ = get_metadata(\n",
    "    metadata_url,\n",
    "    select_by='state',\n",
    "    # selector=['HI', 'PR', 'AK'],\n",
    "    selector=['AK'],\n",
    "\n",
    "    # must_include='identifiers.nws_lid', ## ddin't work oh well\n",
    "    must_include=None,\n",
    "\n",
    "    # must_include='nws_data.rfc_forecast_point',\n",
    "    upstream_trace_distance=nwm_us_search,\n",
    "    downstream_trace_distance=nwm_ds_search,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6ea62763-40ca-4284-a7cd-1f6c6a558b76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input metadata list length: 2047\n",
      "Output (unique) metadata list length: 1950\n",
      "Number of unique LIDs: 1950 \n",
      "Number of duplicate LIDs: 0 \n",
      "Number of None LIDs: 97\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unique_lids, duplicate_lids, nonelid_metadata_list, duplicate_metadata_list, unique_metadata_list =  filter_metadata_list(state_list, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "48ebeb97-42ef-4021-b777-083cf6267e02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filt_list = conus_list[conus_list['identifiers']['nws_lid']=='00RDR']\n",
    "\n",
    "# type(conus_list)\n",
    "\n",
    "# list of dictionaries of dictionaries \n",
    "\n",
    "# type(conus_list[1])\n",
    "\n",
    "# conus_list[1].keys()\n",
    "\n",
    "# conus_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76895cbe-7ce9-47a1-a754-5237955dd396",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List length: 79766\n",
      "Runtime (seconds): 9.806367041999998\n"
     ]
    }
   ],
   "source": [
    "t1_start = process_time() # stopwatch\n",
    " \n",
    "\n",
    "conus_list, ___ = get_metadata(\n",
    "    metadata_url,\n",
    "    select_by='nws_lid',\n",
    "    selector=['all'],\n",
    "    # must_include='nws_data.rfc_forecast_point',\n",
    "    upstream_trace_distance=nwm_us_search,\n",
    "    downstream_trace_distance=nwm_ds_search,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print('List length:', len(conus_list))\n",
    "\n",
    "t1_stop = process_time() # stopwatch\n",
    "print('Runtime (seconds):', t1_stop-t1_start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca99d060-3963-497f-a8c0-cb117bbcd818",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'identifiers': {'nws_lid': '46003',\n",
       "  'usgs_site_code': None,\n",
       "  'nwm_feature_id': None,\n",
       "  'goes_id': None,\n",
       "  'env_can_gage_id': None},\n",
       " 'nws_data': {'name': 'Southern Aleutians',\n",
       "  'wfo': 'AFC',\n",
       "  'rfc': 'APRFC',\n",
       "  'geo_rfc': 'INVALID',\n",
       "  'latitude': 51.851388888889,\n",
       "  'longitude': -155.91583333333,\n",
       "  'map_link': 'https://maps.google.com/maps?t=k&q=loc:51.851388888889+-155.91583333333',\n",
       "  'horizontal_datum_name': 'NAD27',\n",
       "  'state': 'Alaska',\n",
       "  'county': None,\n",
       "  'county_code': None,\n",
       "  'huc': None,\n",
       "  'hsa': 'AFC',\n",
       "  'zero_datum': 0.0,\n",
       "  'vertical_datum_name': None,\n",
       "  'rfc_forecast_point': False,\n",
       "  'rfc_defined_fcst_point': False,\n",
       "  'riverpoint': True},\n",
       " 'usgs_data': {'name': None,\n",
       "  'geo_rfc': None,\n",
       "  'latitude': None,\n",
       "  'longitude': None,\n",
       "  'map_link': None,\n",
       "  'coord_accuracy_code': None,\n",
       "  'latlon_datum_name': None,\n",
       "  'coord_method_code': None,\n",
       "  'state': None,\n",
       "  'huc': None,\n",
       "  'site_type': None,\n",
       "  'altitude': None,\n",
       "  'alt_accuracy_code': None,\n",
       "  'alt_datum_code': None,\n",
       "  'alt_method_code': None,\n",
       "  'drainage_area': None,\n",
       "  'drainage_area_units': 'square miles',\n",
       "  'contrib_drainage_area': None,\n",
       "  'active': None,\n",
       "  'gages_ii_reference': None},\n",
       " 'nwm_feature_data': {'downstream_feature_id': None,\n",
       "  'latitude': None,\n",
       "  'longitude': None,\n",
       "  'altitude': None,\n",
       "  'stream_length': None,\n",
       "  'stream_order': None,\n",
       "  'mannings_roughness': None,\n",
       "  'slope': None,\n",
       "  'channel_side_slope': None,\n",
       "  'nhd_waterbody_comid': None},\n",
       " 'env_can_gage_data': {'name': None,\n",
       "  'latitude': None,\n",
       "  'longitude': None,\n",
       "  'map_link': None,\n",
       "  'drainage_area': None,\n",
       "  'contrib_drainage_area': None,\n",
       "  'water_course': None},\n",
       " 'nws_preferred': {'name': 'Southern Aleutians',\n",
       "  'latitude': 51.851388888889,\n",
       "  'longitude': -155.91583333333,\n",
       "  'latlon_datum_name': 'NAD27',\n",
       "  'state': 'Alaska',\n",
       "  'huc': None},\n",
       " 'usgs_preferred': {'name': 'Southern Aleutians',\n",
       "  'latitude': 51.851388888889,\n",
       "  'longitude': -155.91583333333,\n",
       "  'latlon_datum_name': 'NAD27',\n",
       "  'state': 'Alaska',\n",
       "  'huc': None},\n",
       " 'wrds_timestamp': 'USGS data: USGS NWIS - Last updated: 2024-12-03 22:16:58 UTC',\n",
       " 'nrldb_timestamp': 'NWS data: NRLDB - Last updated: 2024-12-03 22:45:46 UTC',\n",
       " 'nwis_timestamp': 'USGS data: USGS NWIS - Last updated: 2024-12-03 22:16:58 UTC',\n",
       " 'metadata_sources': ['NWS data: NRLDB - Last updated: 2024-12-03 22:45:46 UTC',\n",
       "  'USGS data: USGS NWIS - Last updated: 2024-12-03 22:16:58 UTC'],\n",
       " 'crosswalk_datasets': {'location_nwm_crosswalk_dataset': {'location_nwm_crosswalk_dataset_id': '3.0',\n",
       "   'name': 'Location NWM Crosswalk v3.0',\n",
       "   'description': 'Created 20240328. Authoritative 3.0 dataset mapping Locations to NWM Reaches.  Source:\\n1) NWM Routelink File v3.0\\n2) NHDPlus v2.1+\\n3) GID'},\n",
       "  'nws_usgs_crosswalk_dataset': {'nws_usgs_crosswalk_dataset_id': '3.0',\n",
       "   'name': 'NWS Station to USGS Gages 3.0',\n",
       "   'description': 'Created 20240328.  Authoritative 3.0 dataset mapping NWS Stations to USGS Gage.  Source:\\n1) AHPS CMS Report\\n2) HADS dataset\\n3) GID'}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(islands_list))\n",
    "\n",
    "# islands_list[1]['identifiers']\n",
    "\n",
    "# Get state name\n",
    "# islands_list[1]['nws_data']['state']\n",
    "\n",
    "islands_list[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e396eb-9fe1-44a2-a633-f8997966c48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # local script calls __load_nwm_metadata so FLOG is already setup\n",
    "# def __load_nwm_metadata(\n",
    "#     output_catfim_dir, metadata_url, nwm_us_search, nwm_ds_search, lid_to_run, nwm_metafile\n",
    "# ):\n",
    "\n",
    "#     # FLOG.trace(metadata_url)\n",
    "\n",
    "#     all_meta_lists = []\n",
    "#     # Check to see if meta file already exists\n",
    "#     # This feature means we can copy the pickle file to another enviro (AWS?) as it won't need to call\n",
    "#     # WRDS unless we need a smaller or modified version. This one likely has all nws_lid data.\n",
    "\n",
    "# #     if os.path.isfile(nwm_metafile) is True:\n",
    "# #         FLOG.lprint(f\"Meta file already downloaded and exists at {nwm_metafile}\")\n",
    "\n",
    "# #         with open(nwm_metafile, \"rb\") as p_handle:\n",
    "# #             all_meta_lists = pickle.load(p_handle)\n",
    "\n",
    "# #     else:\n",
    "#         meta_file = os.path.join(output_catfim_dir, \"nwm_metafile.pkl\")\n",
    "\n",
    "#         FLOG.lprint(f\"Meta file will be downloaded and saved at {meta_file}\")\n",
    "\n",
    "#         # lid_to_run could be a single lid or the word \"all\"\n",
    "#         # TODO: lid_to_run functionality... remove? for now, just hard code lid_to_run as \"all\"\n",
    "#         if lid_to_run != \"all\":\n",
    "#             all_meta_lists, ___ = get_metadata(\n",
    "#                 metadata_url,\n",
    "#                 select_by='nws_lid',\n",
    "#                 selector=[lid_to_run],\n",
    "#                 must_include='nws_data.rfc_forecast_point',\n",
    "#                 upstream_trace_distance=nwm_us_search,\n",
    "#                 downstream_trace_distance=nwm_ds_search,\n",
    "#             )\n",
    "#         else:\n",
    "#         conus_list, ___ = get_metadata(\n",
    "#             metadata_url,\n",
    "#             select_by='nws_lid',\n",
    "#             selector=['all'],\n",
    "#             must_include='nws_data.rfc_forecast_point',\n",
    "#             upstream_trace_distance=nwm_us_search,\n",
    "#             downstream_trace_distance=nwm_ds_search,\n",
    "#         )\n",
    "#         # Get metadata for Islands and Alaska\n",
    "#         islands_list, ___ = get_metadata(\n",
    "#             metadata_url,\n",
    "#             select_by='state',\n",
    "#             selector=['HI', 'PR', 'AK'],\n",
    "#             must_include=None,\n",
    "#             upstream_trace_distance=nwm_us_search,\n",
    "#             downstream_trace_distance=nwm_ds_search,\n",
    "#         )\n",
    "#         # Append the lists\n",
    "#         all_meta_lists = conus_list + islands_list\n",
    "\n",
    "#         with open(meta_file, \"wb\") as p_handle:\n",
    "#             pickle.dump(all_meta_lists, p_handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#     return all_meta_lists\n",
    "\n",
    "# all_meta_lists = __load_nwm_metadata(\n",
    "#     output_catfim_dir, metadata_url, nwm_us_search, nwm_ds_search, lid_to_run, nwm_metafile\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5d0836-5596-4ac4-a0a1-98bdbe7cbd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9dc01b-a1d1-473d-963b-242930791f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9a09cc-3a5e-4c9b-a419-ba008f999889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
